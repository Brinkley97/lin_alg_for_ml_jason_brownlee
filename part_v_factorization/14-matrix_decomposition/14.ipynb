{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df24667",
   "metadata": {},
   "source": [
    "# Material\n",
    "\n",
    "## 14.2 What is a Matrix Decomposition\n",
    "- Decomp = Decomposition\n",
    "\n",
    "## 14.3 LU Decomposition\n",
    "## 14.4 QR Decomposition\n",
    "## 14.5 Cholesky Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea3d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.linalg import lu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af457ace",
   "metadata": {},
   "source": [
    "## 14.2 What is a Matrix Decomposition\n",
    "\n",
    "- Also called Matrix factorization bc it's thought of to factor a #; ie 10 can be factored in 2 x 5\n",
    "- More methods than what's below. See [Wiki](https://en.wikipedia.org/wiki/Matrix_decomposition)\n",
    "***\n",
    "\n",
    "### 1. What is MD?\n",
    "\n",
    "1. Matrix Decomposition is reducing/factoring a Matrix into its constituent parts to make it easier to solve\n",
    " \n",
    "2. <b> High-lvl importance (R3 & crew) : </b> Lego blocks (Lb) : Let's say that I build a barrier/wall w/ each wall being a diff color. Your goal is to decompose or sort this structure by the 4 colors bc it's time to clean up.\n",
    "\n",
    "3. <b> Low-lvl importance (Grad student) : </b> Limitations of PCs w/ complex matrix operations result in inefficiency of the computation. \n",
    "\n",
    "4. <b> Additionally : </b> Think about Master of Change book : A $ \\rightarrow $ B $ \\rightarrow $ C, where \n",
    "    - A is the original Matrix, which is complex\n",
    "    - B is the decomposition technique applied to A\n",
    "    - C is the resulting Matrix, which is easier to interpret\n",
    "***\n",
    "\n",
    "### 2. Why is MD important?\n",
    "\n",
    "1. <b> High-lvl importance (R3 & crew) : </b> Possible strategy to clean up is to breakdown wall by wall. Why? To simplify the complexity of breaking down all 4 walls/colors at once.\n",
    "\n",
    "2. <b> Low-lvl importance (Grad student) : </b> To simplify the complex Matrix operation(s), $ \\therefore $ increase the computation efficiency\n",
    "***\n",
    "\n",
    "### 3. What are some applications of MD? What other concepts can I connect to this? Use when...\n",
    "\n",
    "1. Solving sys of linear eqs\n",
    "\n",
    "2. Calc the inverse [see 11.3](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_iv_matrices/11-matrix_operations/11.ipynb)\n",
    "\n",
    "3. Calc the det(D) [see 11.5](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_iv_matrices/11-matrix_operations/11.ipynb)\n",
    "\n",
    "4. [Back propagation](https://arxiv.org/abs/2201.00145)\n",
    "***\n",
    "\n",
    "### 4. What is the evolution of MD? In np?\n",
    "\n",
    "1. [Two Purposes for Matrix Factorization : A Historical Appraisal*](https://www.jstor.org/stable/2653377?seq=1#metadata_info_tab_contents)\n",
    "\n",
    "2. [Matrix Decomposition and Applications](https://arxiv.org/abs/2201.00145)\n",
    "\n",
    "3. [History and generality of the CS decomposition](https://www.sciencedirect.com/science/article/pii/0024379594904464)\n",
    "* TO DO : Read resources along w/ more & type notes here\n",
    "***\n",
    "\n",
    "### 5. Can I predict the future use of MD? How can this current usage improve?\n",
    "\n",
    "* TO DO : Learn more on this\n",
    "***\n",
    "\n",
    "### 6. What don't I understand? Why is this? What's the root of this misunderstanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effef39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b507be8e",
   "metadata": {},
   "source": [
    "## 14.3 LU Decomposition\n",
    "\n",
    "### 1. Why use LUD?\n",
    "1. Only for square Matrices\n",
    "\n",
    "***\n",
    "\n",
    "### 2. How to compute the LUD?\n",
    "1. Notation : A = L $ \\cdot $ U $ \\iff $ A = LU\n",
    "    1. Decomp : A\n",
    "    2. Lower Tria Matrix : L\n",
    "    3. Upper Tria Matrix : U\n",
    "2. See process [here](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_v_factorization/14-matrix_decomposition/luBreakdown.ipynb)\n",
    "*** \n",
    "\n",
    "### 3. Application & concepts to connect\n",
    "1. Finding the coefficients in lin regression\n",
    "\n",
    "2. Calc the inverse [see 11.3](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_iv_matrices/11-matrix_operations/11.ipynb)\n",
    "\n",
    "3. Calc the det(D) [see 11.5](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_iv_matrices/11-matrix_operations/11.ipynb)\n",
    "\n",
    "*** \n",
    "\n",
    "### 4. Other\n",
    "1. LU can fail for Matrices that can't be decomp at all & some that can't be decomp so easily <b> so to aid this use LUP </b> bc it's numerically more stable\n",
    "    1. LUP : LU (as above)\n",
    "    2. P : decomp w/ partial pivoting\n",
    "        - re-ordering the rows of the parent Matrix (A) to simply the decomp process\n",
    "        - returns result to originial order after \n",
    "    3. A = L $ \\cdot $ U $ \\cdot $ P $ \\iff $ A = LUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fae2cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.shape :  (3, 3) \n",
      "D : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "#### FACTOR - DECMOP ####\n",
      "\n",
      ">> P.shape :  (3, 3) \n",
      ">> P : \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]] \n",
      "\n",
      ">> L.shape :  (3, 3) \n",
      ">> L : \n",
      " [[1.         0.         0.        ]\n",
      " [0.14285714 1.         0.        ]\n",
      " [0.57142857 0.5        1.        ]] \n",
      "\n",
      ">> U.shape :  (3, 3) \n",
      ">> U : \n",
      " [[7.         8.         9.        ]\n",
      " [0.         0.85714286 1.71428571]\n",
      " [0.         0.         0.        ]]\n",
      "\n",
      "#### RECONSTRUCT ####\n",
      "\n",
      ">> P_dot_L_dot_U.shape :  (3, 3) \n",
      ">> P_dot_L_dot_U : \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      ">> my_dot.shape :  (3, 3) \n",
      ">> my_dot : \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# 3 x 3 square Matrix\n",
    "D = np.array([\n",
    "             [1, 2, 3],\n",
    "             [4, 5, 6],\n",
    "             [7, 8, 9]\n",
    "             ])\n",
    "print(\"D.shape : \", D.shape, \"\\nD : \\n\", D)\n",
    "\n",
    "print(\"\\n#### FACTOR - DECMOP ####\")\n",
    "\n",
    "P, L, U = sp.linalg.lu(D)\n",
    "print(\"\\n>> P.shape : \", P.shape, \"\\n>> P : \\n\", P, \n",
    "      \"\\n\\n>> L.shape : \", L.shape, \"\\n>> L : \\n\", L, \n",
    "     \"\\n\\n>> U.shape : \", U.shape, \"\\n>> U : \\n\", U\n",
    "     )\n",
    "\n",
    "print(\"\\n#### RECONSTRUCT ####\")\n",
    "P_dot_L_dot_U = P.dot(L).dot(U)\n",
    "print(\"\\n>> P_dot_L_dot_U.shape : \", P_dot_L_dot_U.shape, \"\\n>> P_dot_L_dot_U : \\n\", P_dot_L_dot_U)\n",
    "\n",
    "# another way to write J\n",
    "my_dot = np.dot(np.dot(P, L), U)\n",
    "print(\"\\n>> my_dot.shape : \", my_dot.shape, \"\\n>> my_dot : \\n\", my_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011f9e8",
   "metadata": {},
   "source": [
    "## 14.4 QR Decomposition\n",
    "\n",
    "\n",
    "### 1. Why use QRD?\n",
    "1. Bc it's ! limited to square Matrices\n",
    "2. Bc it's $ \\lnot $ (not) limited to square Matrices\n",
    "3. Returns Q & R Matrices w/ smaller or reduced dims $ \\implies $ more economical/efficient\n",
    "\n",
    "***\n",
    "\n",
    "### 2. How to compute the QRD?\n",
    "1. Notation : A = Q $ \\cdot $ R $ \\iff $ A = QR\n",
    "    1. e $ \\times $ a (Decomp) : A\n",
    "    2. a $ \\times $ a : Q\n",
    "    3. a $ \\times $ e (Upper Tria Matrix) : R\n",
    "2. See process [here](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_v_factorization/14-matrix_decomposition/qrBreakdown.ipynb)\n",
    "\n",
    "- TO DO : figure out why I'm getting\n",
    "    1. w/ out the complete param, \n",
    "        1. e $ \\times $  a : Q\n",
    "        2. a $ \\times $ a (Upper Tria Matrix) : R\n",
    "    2. w/ the complete param,\n",
    "        1. e $ \\times $  e : Q\n",
    "        2. e $ \\times $ a (Upper Tria Matrix) : R\n",
    "*** \n",
    "\n",
    "### 3. Application & concepts to connect\n",
    "1. Solving sys of lin eqs\n",
    "\n",
    "*** \n",
    "\n",
    "### 4. Other\n",
    "1. QRD can fail for Matrices that can't be decomp at all & some that can't be decomp so easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34da0eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.shape :  (3, 2) \n",
      "D : \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "#### FACTOR - DECMOP w/ out the complete arg ####\n",
      "\n",
      ">> Q.shape :  (3, 2) \n",
      ">> Q : \n",
      " [[-0.16903085  0.89708523]\n",
      " [-0.50709255  0.27602622]\n",
      " [-0.84515425 -0.34503278]] \n",
      "\n",
      ">> R.shape :  (2, 2) \n",
      ">> R : \n",
      " [[-5.91607978 -7.43735744]\n",
      " [ 0.          0.82807867]]\n",
      "\n",
      "#### RECONSTRUCT ####\n",
      "\n",
      ">> Q_dot_R.shape :  (3, 2) \n",
      ">> Q_dot_R : \n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "\n",
      "\n",
      "\n",
      "#### FACTOR - DECMOP w/ the complete arg ####\n",
      "\n",
      ">> Q.shape :  (3, 3) \n",
      ">> Q : \n",
      " [[-0.16903085  0.89708523  0.40824829]\n",
      " [-0.50709255  0.27602622 -0.81649658]\n",
      " [-0.84515425 -0.34503278  0.40824829]] \n",
      "\n",
      ">> R.shape :  (3, 2) \n",
      ">> R : \n",
      " [[-5.91607978 -7.43735744]\n",
      " [ 0.          0.82807867]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "#### RECONSTRUCT ####\n",
      "\n",
      ">> Q_dot_R.shape :  (3, 2) \n",
      ">> Q_dot_R : \n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# 3 x 2 square Matrix\n",
    "D = np.array([\n",
    "             [1, 2],\n",
    "             [3, 4],\n",
    "             [5, 6]\n",
    "             ])\n",
    "print(\"D.shape : \", D.shape, \"\\nD : \\n\", D)\n",
    "\n",
    "print(\"\\n#### FACTOR - DECMOP w/ out the complete arg ####\")\n",
    "\n",
    "# complete : ! required but used to return Q & R to expected sizes\n",
    "Q, R = np.linalg.qr(D)\n",
    "print(\"\\n>> Q.shape : \", Q.shape, \"\\n>> Q : \\n\", Q, \n",
    "      \"\\n\\n>> R.shape : \", R.shape, \"\\n>> R : \\n\", R, \n",
    "     )\n",
    "\n",
    "print(\"\\n#### RECONSTRUCT ####\")\n",
    "Q_dot_R = np.dot(Q, R)\n",
    "print(\"\\n>> Q_dot_R.shape : \", Q_dot_R.shape, \"\\n>> Q_dot_R : \\n\", Q_dot_R)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n#### FACTOR - DECMOP w/ the complete arg ####\")\n",
    "\n",
    "# complete : ! required but used to return Q & R to expected sizes\n",
    "Q, R = np.linalg.qr(D, 'complete')\n",
    "print(\"\\n>> Q.shape : \", Q.shape, \"\\n>> Q : \\n\", Q, \n",
    "      \"\\n\\n>> R.shape : \", R.shape, \"\\n>> R : \\n\", R, \n",
    "     )\n",
    "\n",
    "print(\"\\n#### RECONSTRUCT ####\")\n",
    "Q_dot_R = np.dot(Q, R)\n",
    "print(\"\\n>> Q_dot_R.shape : \", Q_dot_R.shape, \"\\n>> Q_dot_R : \\n\", Q_dot_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf9b45",
   "metadata": {},
   "source": [
    "## 14.5 Cholesky Decomposition\n",
    "- Cholesky : co-lesk-kee\n",
    "\n",
    "### 1. Why use CD?\n",
    "1. For square symmetric Matrices where (+) definite Matrix $ \\implies $ all entries > 0\n",
    "2. Nearly 2x efficient as the LUD when performing on symmetical Matrices\n",
    "\n",
    "***\n",
    "\n",
    "### 2. How to compute the CD?\n",
    "1. Notation : A = Q $ \\cdot $ R $ \\iff $ A = QR\n",
    "    1. e $ \\times $ a (Decomp) : A\n",
    "    2. a $ \\times $ a : Q\n",
    "    3. a $ \\times $ e (Upper Tria Matrix) : R\n",
    "\n",
    "1. Notation : A = L $ \\cdot $ L$ ^T $ $ \\iff $ A = LL$ ^T $ $ \\iff $ A = U$ ^T $ $ \\cdot $ U $ \\iff $ A = U$ ^T $ U\n",
    "    1. Decomp : Matrix A\n",
    "    2. Lower tria Matrix : L\n",
    "    3. Lower tria Matrix transpose : L$ ^T $\n",
    "    4. Upper tria Matrix transpose : U$ ^T $\n",
    "    5. Upper tria Matrix : U\n",
    "    6. Returns : L\n",
    "2. See process [here](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/blob/main/part_v_factorization/14-matrix_decomposition/choleskyBreakdown.ipynb)\n",
    "\n",
    "*** \n",
    "\n",
    "### 3. Application & concepts to connect\n",
    "1. Solving lin least squares for lin regression\n",
    "2. Calc simulation & optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9221cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.shape :  (3, 3) \n",
      "D : \n",
      " [[2 1 1]\n",
      " [1 2 1]\n",
      " [1 1 2]]\n",
      "\n",
      "#### FACTOR - DECMOP ####\n",
      "\n",
      ">> L.shape :  (3, 3) \n",
      ">> L : \n",
      " [[1.41421356 0.         0.        ]\n",
      " [0.70710678 1.22474487 0.        ]\n",
      " [0.70710678 0.40824829 1.15470054]]\n",
      "\n",
      "#### RECONSTRUCT ####\n",
      "\n",
      ">> L_T.shape :  (3, 3) \n",
      ">> L_T : \n",
      " [[1.41421356 0.70710678 0.70710678]\n",
      " [0.         1.22474487 0.40824829]\n",
      " [0.         0.         1.15470054]]\n",
      "\n",
      ">> L_dot_L_T.shape :  (3, 3) \n",
      ">> L_dot_L_T : \n",
      " [[2. 1. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# 3 x 3 square Matrix\n",
    "D = np.array([\n",
    "             [2, 1, 1],\n",
    "             [1, 2, 1],\n",
    "             [1, 1, 2]\n",
    "             ])\n",
    "print(\"D.shape : \", D.shape, \"\\nD : \\n\", D)\n",
    "\n",
    "print(\"\\n#### FACTOR - DECMOP ####\")\n",
    "\n",
    "L = np.linalg.cholesky(D)\n",
    "print(\"\\n>> L.shape : \", L.shape, \"\\n>> L : \\n\", L)\n",
    "\n",
    "print(\"\\n#### RECONSTRUCT ####\")\n",
    "\n",
    "L_T = np.transpose(L)\n",
    "print(\"\\n>> L_T.shape : \", L_T.shape, \"\\n>> L_T : \\n\", L_T)\n",
    "\n",
    "L_dot_L_T = np.dot(L, L_T)\n",
    "print(\"\\n>> L_dot_L_T.shape : \", L_dot_L_T.shape, \"\\n>> L_dot_L_T : \\n\", L_dot_L_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ccb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
